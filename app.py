import streamlit as st
from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering
import torch

# Page configuration
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for RTL and styling
st.markdown("""
    <style>
    .main {
        direction: rtl;
        text-align: right;
    }
    .stTextArea textarea {
        direction: rtl;
        text-align: right;
    }
    .stTextInput input {
        direction: rtl;
        text-align: right;
    }
    .answer-box {
        padding: 20px;
        background-color: #d4edda;
        border-radius: 10px;
        border: 2px solid #28a745;
        direction: rtl;
        text-align: right;
        font-size: 18px;
        margin: 10px 0;
    }
    .title {
        text-align: center;
        color: #28a745;
        direction: rtl;
    }
    </style>
""", unsafe_allow_html=True)

# Title
st.markdown("<h1 class='title'>ğŸ¤– Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠ</h1>", unsafe_allow_html=True)
st.markdown("<h3 class='title'>Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù†Ù…ÙˆØ°Ø¬ AraBERT</h3>", unsafe_allow_html=True)
st.markdown("---")

# Sidebar for model configuration
with st.sidebar:
    st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    
    model_option = st.radio(
        "Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:",
        ["Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Hugging Face Hub", "Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠ"]
    )
    
    if model_option == "Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Hugging Face Hub":
        model_name = st.text_input(
            "Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:",
            value="aubmindlab/bert-base-arabertv2",
            help="Ù…Ø«Ø§Ù„: username/model-name Ø£Ùˆ aubmindlab/bert-base-arabertv2"
        )
    else:
        model_path = st.text_input(
            "Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ù„ÙŠ:",
            value="./model",
            help="Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ"
        )
    
    st.markdown("---")
    st.markdown("### ğŸ“– ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…")
    st.markdown("""
    1. Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
    2. Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ
    3. Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
    4. Ø¬Ø±Ø¨ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ù…Ø­Ù…Ù„Ø©
    """)

# Cache the model loading
@st.cache_resource
def load_model(model_name_or_path):
    """Load the QA model and tokenizer"""
    try:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
            tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)
            model = AutoModelForQuestionAnswering.from_pretrained(model_name_or_path)
            qa_pipeline = pipeline(
                "question-answering",
                model=model,
                tokenizer=tokenizer,
                device=0 if torch.cuda.is_available() else -1
            )
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
            return qa_pipeline
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
        return None

# Example data
EXAMPLES = {
    "Ù…Ø«Ø§Ù„ 1: Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©": {
        "context": "Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ù‡Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ø¹Ù‡Ø¯ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ ÙˆÙ†Ø§Ø¦Ø¨ Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ ÙˆÙˆØ²ÙŠØ± Ø§Ù„Ø¯ÙØ§Ø¹. ÙˆÙ„Ø¯ ÙÙŠ 31 Ø£ØºØ³Ø·Ø³ 1985 ÙÙŠ Ø¬Ø¯Ø©. ÙŠØ¹ØªØ¨Ø± Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© 2030ØŒ ÙˆÙ‡ÙŠ Ø®Ø·Ø© Ø·Ù…ÙˆØ­Ø© Ù„ØªÙ†ÙˆÙŠØ¹ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù†ÙØ·.",
        "question": "Ù…ØªÙ‰ ÙˆÙ„Ø¯ Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù†ØŸ"
    },
    "Ù…Ø«Ø§Ù„ 2: Ø§Ù„Ø¹Ù„ÙˆÙ…": {
        "context": "Ø§Ù„Ù…Ø§Ø¡ Ù‡Ùˆ Ù…Ø±ÙƒØ¨ ÙƒÙŠÙ…ÙŠØ§Ø¦ÙŠ ÙŠØªÙƒÙˆÙ† Ù…Ù† Ø°Ø±ØªÙŠÙ† Ù…Ù† Ø§Ù„Ù‡ÙŠØ¯Ø±ÙˆØ¬ÙŠÙ† ÙˆØ°Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ø£ÙƒØ³Ø¬ÙŠÙ†. ÙŠØºØ·ÙŠ Ø§Ù„Ù…Ø§Ø¡ Ø­ÙˆØ§Ù„ÙŠ 71% Ù…Ù† Ø³Ø·Ø­ Ø§Ù„Ø£Ø±Ø¶. Ø¯Ø±Ø¬Ø© ØºÙ„ÙŠØ§Ù† Ø§Ù„Ù…Ø§Ø¡ Ù‡ÙŠ 100 Ø¯Ø±Ø¬Ø© Ù…Ø¦ÙˆÙŠØ© Ø¹Ù†Ø¯ Ù…Ø³ØªÙˆÙ‰ Ø³Ø·Ø­ Ø§Ù„Ø¨Ø­Ø±.",
        "question": "Ù…Ø§ Ù‡ÙŠ Ù†Ø³Ø¨Ø© ØªØºØ·ÙŠØ© Ø§Ù„Ù…Ø§Ø¡ Ù„Ø³Ø·Ø­ Ø§Ù„Ø£Ø±Ø¶ØŸ"
    },
    "Ù…Ø«Ø§Ù„ 3: Ø§Ù„ØªØ§Ø±ÙŠØ®": {
        "context": "ØªØ£Ø³Ø³Øª Ø§Ù„Ø¯ÙˆÙ„Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø¹Ø§Ù… 1744 Ø¹Ù„Ù‰ ÙŠØ¯ Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ø¹ÙˆØ¯. ÙˆÙÙŠ Ø¹Ø§Ù… 1932ØŒ ØªÙ… ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø¹Ù„Ù‰ ÙŠØ¯ Ø§Ù„Ù…Ù„Ùƒ Ø¹Ø¨Ø¯ Ø§Ù„Ø¹Ø²ÙŠØ² Ø¢Ù„ Ø³Ø¹ÙˆØ¯. ØªØ¹ØªØ¨Ø± Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ù…Ù† Ø£ÙƒØ¨Ø± Ø§Ù„Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù†ØªØ¬Ø© Ù„Ù„Ù†ÙØ· ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù….",
        "question": "Ù…Ù† Ù‚Ø§Ù… Ø¨ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŸ"
    }
}

# Example selector
col1, col2 = st.columns([3, 1])
with col2:
    selected_example = st.selectbox(
        "Ø§Ø®ØªØ± Ù…Ø«Ø§Ù„Ø§Ù‹:",
        ["Ù„Ø§ ÙŠÙˆØ¬Ø¯"] + list(EXAMPLES.keys())
    )

# Main content area
col_context, col_question = st.columns(2)

with col_context:
    st.subheader("ğŸ“„ Ø§Ù„Ù†Øµ (Ø§Ù„Ø³ÙŠØ§Ù‚)")
    if selected_example != "Ù„Ø§ ÙŠÙˆØ¬Ø¯":
        context = st.text_area(
            "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„ Ø¹Ù†Ù‡:",
            value=EXAMPLES[selected_example]["context"],
            height=200,
            key="context",
            label_visibility="collapsed"
        )
    else:
        context = st.text_area(
            "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„ Ø¹Ù†Ù‡:",
            height=200,
            key="context",
            label_visibility="collapsed",
            placeholder="Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§..."
        )

with col_question:
    st.subheader("â“ Ø§Ù„Ø³Ø¤Ø§Ù„")
    if selected_example != "Ù„Ø§ ÙŠÙˆØ¬Ø¯":
        question = st.text_input(
            "Ù…Ø§ Ù‡Ùˆ Ø³Ø¤Ø§Ù„ÙƒØŸ",
            value=EXAMPLES[selected_example]["question"],
            key="question",
            label_visibility="collapsed"
        )
    else:
        question = st.text_input(
            "Ù…Ø§ Ù‡Ùˆ Ø³Ø¤Ø§Ù„ÙƒØŸ",
            key="question",
            label_visibility="collapsed",
            placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§..."
        )

# Get Answer button
col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
with col_btn1:
    get_answer = st.button("ğŸ¯ Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©", use_container_width=True, type="primary")
with col_btn2:
    clear_btn = st.button("ğŸ—‘ï¸ Ù…Ø³Ø­", use_container_width=True)

if clear_btn:
    st.rerun()

# Process and display answer
if get_answer:
    if not context.strip() or not question.strip():
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ø³Ø¤Ø§Ù„")
    else:
        # Load model
        if model_option == "Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Hugging Face Hub":
            qa_model = load_model(model_name)
        else:
            qa_model = load_model(model_path)
        
        if qa_model:
            try:
                with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©..."):
                    result = qa_model(question=question, context=context)
                    
                    # Display answer
                    st.markdown("---")
                    st.subheader("âœ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©")
                    st.markdown(
                        f"<div class='answer-box'>{result['answer']}</div>",
                        unsafe_allow_html=True
                    )
                    
                    # Display confidence score
                    col_score1, col_score2, col_score3 = st.columns(3)
                    with col_score2:
                        confidence = result['score'] * 100
                        st.metric("Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©", f"{confidence:.2f}%")
                    
                    # Display additional info
                    with st.expander("ğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©"):
                        st.write(f"**Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ù†Øµ:** Ù…Ù† Ø§Ù„Ø­Ø±Ù {result['start']} Ø¥Ù„Ù‰ {result['end']}")
                        st.write(f"**Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©:** {result['score']:.4f}")
                        
            except Exception as e:
                st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„: {str(e)}")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; direction: rtl;'>
    <p>ØªÙ… Ø¨Ù†Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AraBERT Ùˆ Streamlit</p>
    <p>Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø©</p>
</div>
""", unsafe_allow_html=True)